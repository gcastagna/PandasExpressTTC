{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import seaborn as sn\n",
    "import os\n",
    "import glob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_climate = pd.read_csv('climate_data_raw.csv')\n",
    "\n",
    "script_directory = os.path.dirname(os.path.abspath('geo_delays_1.csv'))\n",
    "\n",
    "# Use glob to find all .csv files in the directory containing 'bus_delay_fuzz'\n",
    "csv_files = glob.glob(os.path.join(script_directory, '*geo_delays*.csv'))\n",
    "\n",
    "# Initialize an empty list to store individual DataFrames\n",
    "dfs = []\n",
    "\n",
    "# Read and append each DataFrame to the list\n",
    "for csv_file in csv_files:\n",
    "    df = pd.read_csv(csv_file)\n",
    "    dfs.append(df)\n",
    "\n",
    "# Concatenate all DataFrames into a single DataFrame\n",
    "df_bus_delays = pd.concat(dfs, ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 588591 entries, 0 to 588590\n",
      "Data columns (total 10 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   Unnamed: 0  588591 non-null  int64  \n",
      " 1   Route       588513 non-null  object \n",
      " 2   Day         588591 non-null  object \n",
      " 3   Location    587798 non-null  object \n",
      " 4   Incident    587656 non-null  object \n",
      " 5   Min Delay   551143 non-null  float64\n",
      " 6   Min Gap     556191 non-null  float64\n",
      " 7   Vehicle     518755 non-null  float64\n",
      " 8   DateTime    577268 non-null  object \n",
      " 9   analysis    587771 non-null  object \n",
      "dtypes: float64(3), int64(1), object(6)\n",
      "memory usage: 44.9+ MB\n"
     ]
    }
   ],
   "source": [
    "df_bus_delays.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 121135 entries, 0 to 121134\n",
      "Data columns (total 22 columns):\n",
      " #   Column             Non-Null Count   Dtype  \n",
      "---  ------             --------------   -----  \n",
      " 0   Unnamed: 0         121135 non-null  int64  \n",
      " 1   LOCAL_HOUR         121135 non-null  int64  \n",
      " 2   WIND_DIRECTION     117371 non-null  float64\n",
      " 3   WINDCHILL          22114 non-null   float64\n",
      " 4   PRECIP_AMOUNT      82143 non-null   float64\n",
      " 5   HUMIDEX            18858 non-null   float64\n",
      " 6   RELATIVE_HUMIDITY  114035 non-null  float64\n",
      " 7   LOCAL_YEAR         121135 non-null  int64  \n",
      " 8   TEMP_FLAG          422 non-null     object \n",
      " 9   UTC_MONTH          121135 non-null  int64  \n",
      " 10  UTC_DAY            121135 non-null  int64  \n",
      " 11  LOCAL_DATE         121135 non-null  object \n",
      " 12  STATION_PRESSURE   120692 non-null  float64\n",
      " 13  TEMP               120712 non-null  float64\n",
      " 14  UTC_YEAR           121135 non-null  int64  \n",
      " 15  WIND_SPEED         120990 non-null  float64\n",
      " 16  LOCAL_DAY          121135 non-null  int64  \n",
      " 17  DEW_POINT_TEMP     120337 non-null  float64\n",
      " 18  LOCAL_MONTH        121135 non-null  int64  \n",
      " 19  UTC_DATE           121135 non-null  object \n",
      " 20  VISIBILITY         120808 non-null  float64\n",
      " 21  weather            121135 non-null  object \n",
      "dtypes: float64(10), int64(8), object(4)\n",
      "memory usage: 20.3+ MB\n"
     ]
    }
   ],
   "source": [
    "df_climate.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert 'LOCAL_DATE' and 'DateTime' columns to datetime objects\n",
    "df_climate['LOCAL_DATE'] = pd.to_datetime(df_climate['LOCAL_DATE'])\n",
    "df_bus_delays['DateTime'] = pd.to_datetime(df_bus_delays['DateTime'])\n",
    "\n",
    "# Find the earliest timestamp in df_bus_delays\n",
    "earliest_timestamp = df_bus_delays['DateTime'].min()\n",
    "\n",
    "# Filter out rows in df_climate before the earliest timestamp\n",
    "df_climate = df_climate[df_climate['LOCAL_DATE'] >= earliest_timestamp]\n",
    "df_bus_delays = df_bus_delays.dropna(subset=['DateTime'])\n",
    "\n",
    "df_bus_delays['temp'] = df_bus_delays['DateTime'].dt.round('H')\n",
    "\n",
    "# Sort both dataframes based on the timestamp\n",
    "df_climate = df_climate.sort_values(by='LOCAL_DATE')\n",
    "df_bus_delays = df_bus_delays.sort_values(by='temp')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Route</th>\n",
       "      <th>Day</th>\n",
       "      <th>Location</th>\n",
       "      <th>Incident</th>\n",
       "      <th>Min Delay</th>\n",
       "      <th>Min Gap</th>\n",
       "      <th>Vehicle</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>analysis</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>York Mills station</td>\n",
       "      <td>Mechanical</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1734.0</td>\n",
       "      <td>2014-01-01 00:23:00</td>\n",
       "      <td>yorkmillsstation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Entire run for route</td>\n",
       "      <td>General Delay</td>\n",
       "      <td>33.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>8110.0</td>\n",
       "      <td>2014-01-01 00:55:00</td>\n",
       "      <td>entirerunforroute</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>lawrence and Warden</td>\n",
       "      <td>Mechanical</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7478.0</td>\n",
       "      <td>2014-01-01 01:28:00</td>\n",
       "      <td>lawrence&amp;warden</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>112</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Kipling Station</td>\n",
       "      <td>Emergency Services</td>\n",
       "      <td>18.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>8084.0</td>\n",
       "      <td>2014-01-01 01:30:00</td>\n",
       "      <td>kiplingstation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>VP and Ellesmere</td>\n",
       "      <td>Investigation</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7843.0</td>\n",
       "      <td>2014-01-01 01:37:00</td>\n",
       "      <td>ellesmere&amp;victoriapark</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0 Route        Day              Location            Incident  \\\n",
       "0           0    95  Wednesday    York Mills station          Mechanical   \n",
       "1           1   102  Wednesday  Entire run for route       General Delay   \n",
       "2           2    54  Wednesday   lawrence and Warden          Mechanical   \n",
       "3           3   112  Wednesday       Kipling Station  Emergency Services   \n",
       "4           4    24  Wednesday      VP and Ellesmere       Investigation   \n",
       "\n",
       "   Min Delay  Min Gap  Vehicle            DateTime                analysis  \n",
       "0       10.0     20.0   1734.0 2014-01-01 00:23:00        yorkmillsstation  \n",
       "1       33.0     66.0   8110.0 2014-01-01 00:55:00       entirerunforroute  \n",
       "2       10.0     20.0   7478.0 2014-01-01 01:28:00         lawrence&warden  \n",
       "3       18.0     36.0   8084.0 2014-01-01 01:30:00          kiplingstation  \n",
       "4       10.0     20.0   7843.0 2014-01-01 01:37:00  ellesmere&victoriapark  "
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_bus_delays.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "ename": "MergeError",
     "evalue": "Passing 'suffixes' which cause duplicate columns {'Unnamed: 0_x'} is not allowed.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMergeError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[6], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m# Merge dataframes based on the closest timestamp\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m merged_df \u001b[38;5;241m=\u001b[39m pd\u001b[38;5;241m.\u001b[39mmerge_asof(\n\u001b[0;32m      3\u001b[0m     df_bus_delays,\n\u001b[0;32m      4\u001b[0m     df_climate,\n\u001b[0;32m      5\u001b[0m     left_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtemp\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Use 'DateTime' as the key for the left dataframe\u001b[39;00m\n\u001b[0;32m      6\u001b[0m     right_on\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLOCAL_DATE\u001b[39m\u001b[38;5;124m'\u001b[39m,  \u001b[38;5;66;03m# Use 'LOCAL_DATE' as the key for the right dataframe\u001b[39;00m\n\u001b[0;32m      7\u001b[0m     direction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mnearest\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m      8\u001b[0m )\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:633\u001b[0m, in \u001b[0;36mmerge_asof\u001b[1;34m(left, right, on, left_on, right_on, left_index, right_index, by, left_by, right_by, suffixes, tolerance, allow_exact_matches, direction)\u001b[0m\n\u001b[0;32m    377\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    378\u001b[0m \u001b[38;5;124;03mPerform a merge by key distance.\u001b[39;00m\n\u001b[0;32m    379\u001b[0m \n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    614\u001b[0m \u001b[38;5;124;03m4 2016-05-25 13:30:00.048   AAPL   98.00       100     NaN     NaN\u001b[39;00m\n\u001b[0;32m    615\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    616\u001b[0m op \u001b[38;5;241m=\u001b[39m _AsOfMerge(\n\u001b[0;32m    617\u001b[0m     left,\n\u001b[0;32m    618\u001b[0m     right,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    631\u001b[0m     direction\u001b[38;5;241m=\u001b[39mdirection,\n\u001b[0;32m    632\u001b[0m )\n\u001b[1;32m--> 633\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m op\u001b[38;5;241m.\u001b[39mget_result()\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:1818\u001b[0m, in \u001b[0;36m_OrderedMerge.get_result\u001b[1;34m(self, copy)\u001b[0m\n\u001b[0;32m   1815\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mget_result\u001b[39m(\u001b[38;5;28mself\u001b[39m, copy: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m DataFrame:\n\u001b[0;32m   1816\u001b[0m     join_index, left_indexer, right_indexer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_get_join_info()\n\u001b[1;32m-> 1818\u001b[0m     llabels, rlabels \u001b[38;5;241m=\u001b[39m _items_overlap_with_suffix(\n\u001b[0;32m   1819\u001b[0m         \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mleft\u001b[38;5;241m.\u001b[39m_info_axis, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mright\u001b[38;5;241m.\u001b[39m_info_axis, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msuffixes\n\u001b[0;32m   1820\u001b[0m     )\n\u001b[0;32m   1822\u001b[0m     left_join_indexer: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m   1823\u001b[0m     right_join_indexer: np\u001b[38;5;241m.\u001b[39mndarray \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[1;32m~\\anaconda3\\Lib\\site-packages\\pandas\\core\\reshape\\merge.py:2640\u001b[0m, in \u001b[0;36m_items_overlap_with_suffix\u001b[1;34m(left, right, suffixes)\u001b[0m\n\u001b[0;32m   2638\u001b[0m     dups\u001b[38;5;241m.\u001b[39mextend(rlabels[(rlabels\u001b[38;5;241m.\u001b[39mduplicated()) \u001b[38;5;241m&\u001b[39m (\u001b[38;5;241m~\u001b[39mright\u001b[38;5;241m.\u001b[39mduplicated())]\u001b[38;5;241m.\u001b[39mtolist())\n\u001b[0;32m   2639\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m dups:\n\u001b[1;32m-> 2640\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m MergeError(\n\u001b[0;32m   2641\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPassing \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msuffixes\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m which cause duplicate columns \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mset\u001b[39m(dups)\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   2642\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnot allowed.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m   2643\u001b[0m     )\n\u001b[0;32m   2645\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m llabels, rlabels\n",
      "\u001b[1;31mMergeError\u001b[0m: Passing 'suffixes' which cause duplicate columns {'Unnamed: 0_x'} is not allowed."
     ]
    }
   ],
   "source": [
    "# Merge dataframes based on the closest timestamp\n",
    "merged_df = pd.merge_asof(\n",
    "    df_bus_delays,\n",
    "    df_climate,\n",
    "    left_on='temp',  # Use 'DateTime' as the key for the left dataframe\n",
    "    right_on='LOCAL_DATE',  # Use 'LOCAL_DATE' as the key for the right dataframe\n",
    "    direction='nearest'\n",
    ")\n",
    "\n",
    "# Drop duplicate columns, keeping only one of the timestamp columns\n",
    "#merged_df = merged_df.drop(columns='LOCAL_DATE')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_df['time_deviation'] = merged_df['temp'] - merged_df['LOCAL_DATE']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Timedelta('0 days 04:00:00')"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df['time_deviation'].max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_chunks = 10\n",
    "chunk_size = len(merged_df) // num_chunks\n",
    "\n",
    "# Save each chunk into a separate CSV file\n",
    "for i in range(num_chunks):\n",
    "    start_idx = i * chunk_size\n",
    "    end_idx = (i + 1) * chunk_size if i < num_chunks - 1 else len(merged_df)\n",
    "    \n",
    "    chunk_df = merged_df.iloc[start_idx:end_idx]\n",
    "    \n",
    "    # Save the chunk to a CSV file with a sequential number\n",
    "    chunk_df.to_csv(f'analysis_data_{i + 1}.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0_x</th>\n",
       "      <th>Route</th>\n",
       "      <th>Day</th>\n",
       "      <th>Location</th>\n",
       "      <th>Incident</th>\n",
       "      <th>Min Delay</th>\n",
       "      <th>Min Gap</th>\n",
       "      <th>Vehicle</th>\n",
       "      <th>DateTime</th>\n",
       "      <th>analysis</th>\n",
       "      <th>...</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>UTC_YEAR</th>\n",
       "      <th>WIND_SPEED</th>\n",
       "      <th>LOCAL_DAY</th>\n",
       "      <th>DEW_POINT_TEMP</th>\n",
       "      <th>LOCAL_MONTH</th>\n",
       "      <th>UTC_DATE</th>\n",
       "      <th>VISIBILITY</th>\n",
       "      <th>weather</th>\n",
       "      <th>time_deviation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>95</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>York Mills station</td>\n",
       "      <td>Mechanical</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>1734.0</td>\n",
       "      <td>2014-01-01 00:23:00</td>\n",
       "      <td>yorkmillsstation</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>2014</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-14.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-01T06:00:00</td>\n",
       "      <td>16.1</td>\n",
       "      <td>dry</td>\n",
       "      <td>-1 days +23:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>102</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Entire run for route</td>\n",
       "      <td>General Delay</td>\n",
       "      <td>33.0</td>\n",
       "      <td>66.0</td>\n",
       "      <td>8110.0</td>\n",
       "      <td>2014-01-01 00:55:00</td>\n",
       "      <td>entirerunforroute</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>2014</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-14.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-01T06:00:00</td>\n",
       "      <td>16.1</td>\n",
       "      <td>dry</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>54</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>lawrence and Warden</td>\n",
       "      <td>Mechanical</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7478.0</td>\n",
       "      <td>2014-01-01 01:28:00</td>\n",
       "      <td>lawrenceave&amp;wardenave</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.2</td>\n",
       "      <td>2014</td>\n",
       "      <td>39.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-14.5</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-01T06:00:00</td>\n",
       "      <td>16.1</td>\n",
       "      <td>dry</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>112</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>Kipling Station</td>\n",
       "      <td>Emergency Services</td>\n",
       "      <td>18.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>8084.0</td>\n",
       "      <td>2014-01-01 01:30:00</td>\n",
       "      <td>kiplingstation</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.6</td>\n",
       "      <td>2014</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-14.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-01T07:00:00</td>\n",
       "      <td>16.1</td>\n",
       "      <td>dry</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>24</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>VP and Ellesmere</td>\n",
       "      <td>Investigation</td>\n",
       "      <td>10.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>7843.0</td>\n",
       "      <td>2014-01-01 01:37:00</td>\n",
       "      <td>ellesmererd&amp;victoriaparkave</td>\n",
       "      <td>...</td>\n",
       "      <td>-8.6</td>\n",
       "      <td>2014</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1</td>\n",
       "      <td>-14.4</td>\n",
       "      <td>1</td>\n",
       "      <td>2014-01-01T07:00:00</td>\n",
       "      <td>16.1</td>\n",
       "      <td>dry</td>\n",
       "      <td>0 days 00:00:00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 34 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0_x Route        Day              Location            Incident  \\\n",
       "0             0    95  Wednesday    York Mills station          Mechanical   \n",
       "1             1   102  Wednesday  Entire run for route       General Delay   \n",
       "2             2    54  Wednesday   lawrence and Warden          Mechanical   \n",
       "3             3   112  Wednesday       Kipling Station  Emergency Services   \n",
       "4             4    24  Wednesday      VP and Ellesmere       Investigation   \n",
       "\n",
       "   Min Delay  Min Gap  Vehicle            DateTime  \\\n",
       "0       10.0     20.0   1734.0 2014-01-01 00:23:00   \n",
       "1       33.0     66.0   8110.0 2014-01-01 00:55:00   \n",
       "2       10.0     20.0   7478.0 2014-01-01 01:28:00   \n",
       "3       18.0     36.0   8084.0 2014-01-01 01:30:00   \n",
       "4       10.0     20.0   7843.0 2014-01-01 01:37:00   \n",
       "\n",
       "                      analysis  ... TEMP  UTC_YEAR  WIND_SPEED  LOCAL_DAY  \\\n",
       "0             yorkmillsstation  ... -8.2      2014        39.0          1   \n",
       "1            entirerunforroute  ... -8.2      2014        39.0          1   \n",
       "2        lawrenceave&wardenave  ... -8.2      2014        39.0          1   \n",
       "3               kiplingstation  ... -8.6      2014        30.0          1   \n",
       "4  ellesmererd&victoriaparkave  ... -8.6      2014        30.0          1   \n",
       "\n",
       "   DEW_POINT_TEMP  LOCAL_MONTH             UTC_DATE  VISIBILITY  weather  \\\n",
       "0           -14.5            1  2014-01-01T06:00:00        16.1      dry   \n",
       "1           -14.5            1  2014-01-01T06:00:00        16.1      dry   \n",
       "2           -14.5            1  2014-01-01T06:00:00        16.1      dry   \n",
       "3           -14.4            1  2014-01-01T07:00:00        16.1      dry   \n",
       "4           -14.4            1  2014-01-01T07:00:00        16.1      dry   \n",
       "\n",
       "     time_deviation  \n",
       "0 -1 days +23:00:00  \n",
       "1   0 days 00:00:00  \n",
       "2   0 days 00:00:00  \n",
       "3   0 days 00:00:00  \n",
       "4   0 days 00:00:00  \n",
       "\n",
       "[5 rows x 34 columns]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
